pg_replication:
  query: "SELECT CASE WHEN NOT pg_is_in_recovery() THEN 0 ELSE GREATEST (0, EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))) END AS lag"
  master: true
  metrics:
    - lag:
        usage: "GAUGE"
        description: "Replication lag behind master in seconds"

pg_postmaster:
  query: "SELECT pg_postmaster_start_time AS start_time_seconds FROM pg_postmaster_start_time()"
  master: true
  metrics:
    - start_time_seconds:
        usage: "GAUGE"
        description: "Time as which postmaster started"

pg_stat_user_tables:
  query: |
   SELECT
     current_database() datname,
     schemaname,
     relname,
     seq_scan,
     seq_tup_read,
     idx_scan,
     idx_tup_fetch,
     n_tup_ins,
     n_tup_upd,
     n_tup_del,
     n_tup_hot_upd,
     n_live_tup,
     n_dead_tup,
     n_mod_since_analyze,
     COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,
     COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,
     COALESCE(last_analyze, '1970-01-01Z') as last_analyze,
     COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,
     vacuum_count,
     autovacuum_count,
     analyze_count,
     autoanalyze_count
   FROM
     pg_stat_user_tables
  metrics:
    - datname:
        usage: "LABEL"
        description: "Name of current database"
    - schemaname:
        usage: "LABEL"
        description: "Name of the schema that this table is in"
    - relname:
        usage: "LABEL"
        description: "Name of this table"
    - seq_scan:
        usage: "COUNTER"
        description: "Number of sequential scans initiated on this table"
    - seq_tup_read:
        usage: "COUNTER"
        description: "Number of live rows fetched by sequential scans"
    - idx_scan:
        usage: "COUNTER"
        description: "Number of index scans initiated on this table"
    - idx_tup_fetch:
        usage: "COUNTER"
        description: "Number of live rows fetched by index scans"
    - n_tup_ins:
        usage: "COUNTER"
        description: "Number of rows inserted"
    - n_tup_upd:
        usage: "COUNTER"
        description: "Number of rows updated"
    - n_tup_del:
        usage: "COUNTER"
        description: "Number of rows deleted"
    - n_tup_hot_upd:
        usage: "COUNTER"
        description: "Number of rows HOT updated (i.e., with no separate index requiered)"
    - n_live_tup:
        usage: "GAUGE"
        description: "Estimated number of live rows"
    - n_dead_tup:
        usage: "GAUGE"
        description: "Estimated number of dead rows"
    - n_mod_since_analyze:
        usage: "GAUGE"
        description: "Estimated numberof rows changed since last analyze"
    - last_vacuum:
        usage: "GAUGE"
        description: "Last time at which this table was manually vacuumed (not counting VACUUM FULL)"
    - last_autovacuum:
        usage: "GAUGE"
        description: "Last time at which this table was vacuumed by the autovacuum daemon"
    - last_analyze:
        usage: "GAUGE"
        description: "Last time at which this table was manually analyzed" 
    - last_autoanalyze:
        usage: "GAUGE"
        description: "Last time at which this table was analyzed by autovacuum daemon"
    - vacuum_count:
        usage: "COUNTER"
        description: "Number of times this table has been manually vacuumed (not counting VACUUM FULL)"
    - autovacuum_count:
        usage: "COUNTER"
        description: "Number of times this table has been vacuumed by the autovacuum daemon"
    - analyze_count:
        usage: "COUNTER"
        description: "Number of times this table has been manually analyzed"
    - autoanalyze_count:
        usage: "COUNTER"
        description: "Number of times this table has been analyzed by the autovacuum daemon"

#current_database() datname: Возвращает имя текущей базы данных.
#schemaname: Название схемы таблицы.
#relname: Название таблицы.
#seq_scan: Количество последовательных (линейных) сканирований таблицы.
#seq_tup_read: Количество строк, прочитанных при последовательном сканировании.
#idx_scan: Количество индексных сканирований таблицы.
#idx_tup_fetch: Количество строк, полученных при помощи индексного сканирования.
#n_tup_ins: Количество вставленных строк.
#n_tup_upd: Количество обновленных строк.
#n_tup_del: Количество удаленных строк.
#n_tup_hot_upd: Количество "горячих" обновлений строк (обновления, которые не приводят к созданию мертвых строк).
#n_live_tup: Количество живых строк в таблице.
#n_dead_tup: Количество мертвых строк в таблице.
#n_mod_since_analyze: Количество изменений строк с момента последнего анализа.
#last_vacuum, last_autovacuum, last_analyze, last_autoanalyze: Время последних операций очистки и анализа, выполненных вручную или автоматически.
#vacuum_count, autovacuum_count, analyze_count, autoanalyze_count: Количество выполненных операций очистки и анализа, выполненных вручную или автоматически.

pg_statio_user_tables:
  query: "SELECT current_database() datname, schemaname, relname, heap_blks_read, heap_blks_hit, idx_blks_read, idx_blks_hit, toast_blks_read, toast_blks_hit, tidx_blks_read, tidx_blks_hit FROM pg_statio_user_tables"
  metrics:
    - datname:
        usage: "LABEL"
        description: "Name of current database"
    - schemaname:
        usage: "LABEL"
        description: "Name of the schema that this table is in"
    - relname:
        usage: "LABEL"
        description: "Name of this table"
    - heap_blks_read:
        usage: "COUNTER"
        description: "Number of disk blocks read from this table"
    - heap_blks_hit:
        usage: "COUNTER"
        description: "Number of buffer hits in this table"
    - idx_blks_read:
        usage: "COUNTER"
        description: "Number of disk blocks read from all indexes on this table"
    - idx_blks_hit:
        usage: "COUNTER"
        description: "Number of buffer hits in all indexes on this table"
    - toast_blks_read:
        usage: "COUNTER"
        description: "Number of disk blocks read from this table's TOAST table (if any)"
    - toast_blks_hit:
        usage: "COUNTER"
        description: "Number of buffer hits in this table's TOAST table (if any)"
    - tidx_blks_read:
        usage: "COUNTER"
        description: "Number of disk blocks read from this table's TOAST table indexes (if any)"
    - tidx_blks_hit:
        usage: "COUNTER"
        description: "Number of buffer hits in this table's TOAST table indexes (if any)"

#current_database() datname: Возвращает имя текущей базы данных.
#schemaname: Название схемы таблицы.
#relname: Название таблицы.
#heap_blks_read: Количество блоков данных, прочитанных из диска.
#heap_blks_hit: Количество блоков данных, прочитанных из кэша (буфера).
#idx_blks_read: Количество блоков индекса, прочитанных из диска.
#idx_blks_hit: Количество блоков индекса, прочитанных из кэша.
#toast_blks_read: Количество блоков TOAST, прочитанных из диска. TOAST — это механизм, который PostgreSQL использует для хранения больших данных.
#toast_blks_hit: Количество блоков TOAST, прочитанных из кэша.
#tidx_blks_read: Количество блоков TOAST-индекса, прочитанных из диска.
#tidx_blks_hit: Количество блоков TOAST-индекса, прочитанных из кэша.



#pg_stat_statements:
#  query: |
#   SELECT
#    pg_get_userbyid(userid) as user,
#    pg_database.datname,
#    pg_stat_statements.queryid,
#    pg_stat_statements.calls as calls_total,
#    pg_stat_statements.total_time / 1000.0 as seconds_total,
#    pg_stat_statements.rows as rows_total,
#    pg_stat_statements.blk_read_time / 1000.0 as block_read_seconds_total,
#    pg_stat_statements.blk_write_time / 1000.0 as block_write_seconds_total
#    FROM pg_stat_statements
#    JOIN pg_database
#      ON pg_database.oid = pg_stat_statements.dbid
#    WHERE
#      total_time > (
#        SELECT percentile_cont(0.1)
#          WITHIN GROUP (ORDER BY total_time)
#          FROM pg_stat_statements
#      )
#    ORDER BY seconds_total DESC
#    LIMIT 100
#  metrics:
#    - user:
#        usage: "LABEL"
#        description: "The user who executed the statement"
#    - datname:
#        usage: "LABEL"
#        description: "The database in which the statement was executed"
#    - queryid:
#        usage: "LABEL"
#        description: "Internal hash code? computed from the statement's parse tree"
#    - calls_total:
#        usage: "COUNTER"
#        description: "Number of times executed"
#    - seconds_total:
#        usage: "COUNTER"
#        description: "Total time spent in the statement, in seconds"
#    - rows_total:
#        usage: "COUNTER"
#        description: "Total number of rows retrieved or affected by the statement"
#    - block_read_seconds_total:
#        usage: "COUNTER"
#        description: "Total time the statement spent reading blocks, in seconds"
#    - block_write_seconds_total:
#        usage: "COUNTER"
#        description: "Total time the statement spent writing blocks, in seconds"

##pg_get_userbyid(userid) as user: Получение имени пользователя, который выполнил запрос. Идентификатор пользователя (userid) преобразуется в имя пользователя функцией pg_get_userbyid.
##pg_database.datname: Имя базы данных, в которой был выполнен запрос.
##pg_stat_statements.queryid: Идентификатор запроса. Он уникален для каждого уникального текста запроса.
##pg_stat_statements.calls as calls_total: Общее количество вызовов данного SQL-запроса.
##pg_stat_statements.total_time / 1000.0 as seconds_total: Общее время выполнения данного запроса в секундах.
##pg_stat_statements.rows as rows_total: Общее количество строк, возвращенных этим запросом.
##pg_stat_statements.blk_read_time / 1000.0 as block_read_seconds_total: Общее время чтения дисковых блоков этим запросом в секундах.
##pg_stat_statements.blk_write_time / 1000.0 as block_write_seconds_total: Общее время записи на диск этим запросом в секундах.
##percentile_cont(0.1):  выбор 10% самых долго выполняемых запросов.

pg_process_idle:
  query: |
    WITH
      metrics AS (
        SELECT
          application_name,
          SUM(EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change))::bigint)::float AS process_idle_seconds_sum,
          COUNT(*) AS process_idle_seconds_count
        FROM pg_stat_activity
        WHERE state = 'idle'
        GROUP BY application_name
      ),
      buckets AS (
        SELECT
          application_name,
          le,
          SUM(
            CASE WHEN EXTRACT(EPOCH FROM (CURRENT_TIMESTAMP - state_change)) <= le
              THEN 1
              ELSE 0
            END
          )::bigint AS bucket
        FROM
          pg_stat_activity,
          UNNEST(ARRAY[1, 2, 5, 15, 30, 60, 90, 120, 300]) AS le
        GROUP BY application_name, le
        ORDER BY application_name, le
      )
    SELECT
      application_name,
      process_idle_seconds_sum as seconds_sum,
      process_idle_seconds_count as seconds_count,
      ARRAY_AGG(le) AS seconds,
      ARRAY_AGG(bucket) AS seconds_bucket
    FROM metrics JOIN buckets USING (application_name)
    GROUP BY 1, 2, 3
  metrics:
    - application_name:
        usage: "LABEL"
        description: "Application Name"
    - seconds:
        usage: "HISTOGRAM"
        description: "Idle time of server processes"


#metrics AS (...): В этом подзапросе выбираются все процессы, которые в данный момент 
#находятся в состоянии 'idle' (ожидание), и для каждого приложения подсчитывается общее время 
#простоя и количество таких процессов.

#buckets AS (...): В этом подзапросе генерируются "бакеты" времени для каждого приложения, 
#каждый из которых представляет собой количество процессов, которые простаивали 
#не более указанного количества секунд. Например, бакет 1 содержит количество процессов, 
#которые простаивали не более 1 секунды, бакет 2 - не более 2 секунд и т.д.

#SELECT application_name, process_idle_seconds_sum as seconds_sum, process_idle_seconds_count as seconds_count, ARRAY_AGG(le) AS seconds, ARRAY_AGG(bucket) AS seconds_bucket FROM metrics JOIN buckets USING (application_name) GROUP BY 1, 2, 3: 
#Здесь мы объединяем результаты из обоих подзапросов по имени приложения, 
#и группируем результаты по имени приложения, общему времени простоя и количеству процессов простоя. 
#Массивы seconds и seconds_bucket формируются из значений le и bucket соответственно.